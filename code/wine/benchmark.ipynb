{
 "cells": [
  {
   "source": [
    "# Wine Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../')\n",
    "import deep_forest\n",
    "import torch as th\n",
    "from torch import nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from math import pi\n",
    "import seaborn as sns\n",
    "from preprocess import get_data\n",
    "sns.set_theme(\"notebook\")\n",
    "sns.set_style('whitegrid')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "## Get Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, test_data, test_labels = get_data(100)"
   ]
  },
  {
   "source": [
    "# Deep F #"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deep_forest.DeepForest(25, 2, 13, 0.25, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====EPOCH 0====\n",
      "Acc: tensor(0.3989)\n",
      "Loss: tensor([167.4655], grad_fn=<AddBackward0>)\n",
      "====EPOCH 200====\n",
      "Acc: tensor(0.6798)\n",
      "Loss: tensor([163.0257], grad_fn=<AddBackward0>)\n",
      "====EPOCH 400====\n",
      "Acc: tensor(0.9101)\n",
      "Loss: tensor([160.8562], grad_fn=<AddBackward0>)\n",
      "====EPOCH 600====\n",
      "Acc: tensor(0.9326)\n",
      "Loss: tensor([159.4335], grad_fn=<AddBackward0>)\n",
      "====EPOCH 800====\n",
      "Acc: tensor(0.9775)\n",
      "Loss: tensor([159.3911], grad_fn=<AddBackward0>)\n",
      "====EPOCH 1000====\n",
      "Acc: tensor(0.9719)\n",
      "Loss: tensor([158.9085], grad_fn=<AddBackward0>)\n",
      "====EPOCH 1200====\n",
      "Acc: tensor(0.9831)\n",
      "Loss: tensor([159.2259], grad_fn=<AddBackward0>)\n",
      "====EPOCH 1400====\n",
      "Acc: tensor(0.9831)\n",
      "Loss: tensor([159.0055], grad_fn=<AddBackward0>)\n",
      "\n",
      "==============\n",
      "FINAL TRAIN ACC: tensor(0.9944)\n",
      "\n",
      "==============\n",
      "FINAL TEST ACC: tensor(0.9944)\n"
     ]
    }
   ],
   "source": [
    "optimizer = th.optim.Adam(model.parameters())\n",
    "pbar = tqdm(range(2500))\n",
    "for i in pbar:\n",
    "    model.populate_best(x[:, :], y[:])\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = model.loss(x[:, :], y[:], device)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pbar.set_description(\"EPOCH %d || Acc: %s || Loss: %s\" % (i, str(th.mean((model.forward(x[:, :], device) == y[:]).float())), str(loss)))\n",
    "\n",
    "print(\"\\n\\n==============\\nFINAL ACC: %s\" % str(th.mean((model.forward(x[:, :], device) == y[:]).float())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = model.compute_importance(x)\n",
    "print()\n",
    "print(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame({\"feat\": list(imp.keys()), \"imp\": list(imp.values())})\n",
    "sns.barplot(x=\"feat\", y=\"imp\", data=data)"
   ]
  },
  {
   "source": [
    "## MLP Baseline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = nn.Sequential(\n",
    "    nn.Linear(7, 30),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(30, 15),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(15, 2),\n",
    "    nn.Softmax()\n",
    ")\n",
    "\n",
    "optimizer = th.optim.Adam(mlp.parameters())\n",
    "pbar = tqdm(range(1000))\n",
    "for i in pbar:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    preds = mlp(x)\n",
    "    loss = nn.functional.cross_entropy(preds, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pbar.set_description(\"EPOCH %d || Acc: %s || Loss: %s\" % (i, str(th.mean((th.argmax(mlp(x), 1) == y).float())), str(loss)))\n",
    "\n",
    "print(\"\\n\\n==============\\nFINAL ACC: %s\" % str(th.mean((th.argmax(mlp(x[:]), 1) == y[:]).float())))"
   ]
  },
  {
   "source": [
    "## Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Accuracy:  0.9831460674157303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2)\n",
    "clf.fit(x.numpy(), y.numpy())\n",
    "print(clf.score(x.numpy(), y.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"feat\": list(range(30)), \"imp\": clf.feature_importances_})\n",
    "sns.barplot(x=\"feat\", y=\"imp\", data=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}